{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1sFrX_SiNgv1"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "words = ['eats','ability','ate','adjustable','meeting']\n",
        "for word in words:\n",
        "  print(f'word= {word} | {stemmer.stem(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3kTNKiNOUg_",
        "outputId": "43260d3f-b5f2-47da-ae21-82e5fed56b03"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word= eats | eat\n",
            "word= ability | abil\n",
            "word= ate | ate\n",
            "word= adjustable | adjust\n",
            "word= meeting | meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"eats ability ate adjustable meeting\")\n",
        "for token in doc:\n",
        "  print(token , '|' ,token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO_XQkoJOUjR",
        "outputId": "9694eb45-da11-4008-92ec-9c09fdc630f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eats | eat\n",
            "ability | ability\n",
            "ate | eat\n",
            "adjustable | adjustable\n",
            "meeting | meeting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise**\n",
        "Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
        "Write a short note on the words that have different base words using stemming and Lemmatization\n"
      ],
      "metadata": {
        "id": "MzqQwiO2azoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using stemming in nltk\n",
        "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
      ],
      "metadata": {
        "id": "M7KGvqskOUlb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in lst_words:\n",
        "  print(word , '|' , stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKQULYx-OUnh",
        "outputId": "28c34982-2cf0-4132-90cb-891d19cffa4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running | run\n",
            "painting | paint\n",
            "walking | walk\n",
            "dressing | dress\n",
            "likely | like\n",
            "children | children\n",
            "whom | whom\n",
            "good | good\n",
            "ate | ate\n",
            "fishing | fish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
        "for token in doc:\n",
        "  print(token , '|' , token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkZ2WyblbQFz",
        "outputId": "13ab9f57-695b-49ed-b941-9bb30994b379"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running | run\n",
            "painting | paint\n",
            "walking | walk\n",
            "dressing | dress\n",
            "likely | likely\n",
            "children | child\n",
            "who | who\n",
            "good | good\n",
            "ate | eat\n",
            "fishing | fishing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the given text into it's base form using both stemming and lemmatization\n",
        "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a\n",
        "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
        "\"\"\"\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.word_tokenize(text)\n",
        "for word in tokens:\n",
        "  print(word, '|',stemmer.stem(word))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob8sJGa_bu4y",
        "outputId": "e1007ade-0290-4c9c-f3db-33443b67dedb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latha | latha\n",
            "is | is\n",
            "very | veri\n",
            "multi | multi\n",
            "talented | talent\n",
            "girl.She | girl.sh\n",
            "is | is\n",
            "good | good\n",
            "at | at\n",
            "many | mani\n",
            "skills | skill\n",
            "like | like\n",
            "dancing | danc\n",
            ", | ,\n",
            "running | run\n",
            ", | ,\n",
            "singing | sing\n",
            ", | ,\n",
            "playing.She | playing.sh\n",
            "also | also\n",
            "likes | like\n",
            "eating | eat\n",
            "Pav | pav\n",
            "Bhagi | bhagi\n",
            ". | .\n",
            "she | she\n",
            "has | ha\n",
            "a | a\n",
            "habit | habit\n",
            "of | of\n",
            "fishing | fish\n",
            "and | and\n",
            "swimming | swim\n",
            "too.Besides | too.besid\n",
            "all | all\n",
            "this | thi\n",
            ", | ,\n",
            "she | she\n",
            "is | is\n",
            "a | a\n",
            "wonderful | wonder\n",
            "at | at\n",
            "cooking | cook\n",
            "too | too\n",
            ". | .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in  doc:\n",
        "  print(token, '|', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl7WvVXXdlT1",
        "outputId": "e36bd6db-bf2f-4652-8c24-8a58e8c29cf3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latha | Latha\n",
            "is | be\n",
            "very | very\n",
            "multi | multi\n",
            "talented | talented\n",
            "girl | girl\n",
            ". | .\n",
            "She | she\n",
            "is | be\n",
            "good | good\n",
            "at | at\n",
            "many | many\n",
            "skills | skill\n",
            "like | like\n",
            "dancing | dancing\n",
            ", | ,\n",
            "running | running\n",
            ", | ,\n",
            "singing | singing\n",
            ", | ,\n",
            "playing | play\n",
            ". | .\n",
            "She | she\n",
            "also | also\n",
            "likes | like\n",
            "eating | eat\n",
            "Pav | Pav\n",
            "Bhagi | Bhagi\n",
            ". | .\n",
            "she | she\n",
            "has | have\n",
            "a | a\n",
            "\n",
            " | \n",
            "\n",
            "habit | habit\n",
            "of | of\n",
            "fishing | fishing\n",
            "and | and\n",
            "swimming | swim\n",
            "too | too\n",
            ". | .\n",
            "Besides | besides\n",
            "all | all\n",
            "this | this\n",
            ", | ,\n",
            "she | she\n",
            "is | be\n",
            "a | a\n",
            "wonderful | wonderful\n",
            "at | at\n",
            "cooking | cook\n",
            "too | too\n",
            ". | .\n",
            "\n",
            " | \n",
            "\n"
          ]
        }
      ]
    }
  ]
}